---
id: 104
version: v1.11.0
date: Released on 3rd October 2025.
---

## Features

### Data Quality as Code

Define and execute data quality tests programmatically using Python, with results automatically published to OpenMetadata's Data Observability dashboard. Integrate validation directly into your transformation pipelines with circuit breaker patterns to prevent bad data from reaching production tables.

Two validation approaches:

- TestRunner --- Validate data already loaded in tables. Reference any table by its fully qualified name (FQN), add any test cases, then execute tests and automatically push results back to OpenMetadata. Ideal for post-load validation and monitoring.

- DataFrameValidator --- Validate data inline during ETL pipelines. Acts as a circuit breaker to prevent bad data from being loaded. Define on_success and on_failure callbacks to control pipeline behavior. Supports chunked processing for large datasets. Optionally publish results to a specific table in OpenMetadata.

What happens when tests run:

Results automatically sync to OpenMetadata's Data Quality tab. Failed tests generate incidents with detailed failure reasons (e.g., "minimum value below zero: -521"). Incident alert icons appear on affected tables. The Overview tab shows passing and failing dimensions at a glance.

Why use it:

Centralize data quality test logic in version control tools. Provide reusable validation libraries for data engineers. Execute tests as part of your pipeline, not as a separate process. Maintain visibility in Collate while managing logic externally.

### Data Quality Dimensionality

You can now create dimension-level data quality tests that automatically segment results by categorical column values, providing granular visibility into data quality across different data segments.

What's New:

When adding a test case in the Data Observability tab, select "Dimension Level" to associate one or more dimension columns (e.g., status, region, product category) with your column-level test. The new configuration panel provides guidance on use cases and allows you to select multiple dimensions for multi-dimensional analysis.

Test cases with dimensions display a badge indicator showing the number of associated dimensions, making them easy to identify in your test case list.

A new "Dimensionality" tab in test results provides:

- A calendar heatmap showing pass/fail status across all dimension values over time

- A summary table with status, impact score, dimension value, and last run timestamp for each segment

- Drill-down capability to view historical execution trends for any specific dimension value

Impact scores help you quickly identify which dimension values are contributing the most failures based on affected row counts.

Why It Matters:

Previously, testing data quality across different categorical segments required writing custom SQL queries (e.g., SELECT ... WHERE status = 'completed') and maintaining separate test cases for each known value. When new dimension values appeared in your data, you had to manually create additional tests. With dimension-level test cases, a single test automatically covers all current and future values in your dimension column, eliminating maintenance overhead while providing deeper insights into where data quality issues occur.

### Notification Templates

You can now fully customize the content and format of alert notifications delivered to Slack, Microsoft Teams, Google Chat, or email.

Manage templates globally or per-alert

Navigate to Settings → Notifications → Templates to view and manage all notification templates. From here you can edit system default templates (which apply globally) or create new reusable templates available across your organization.

Build dynamic templates with placeholders

Use double curly brace syntax to insert dynamic fields that automatically populate when alerts trigger:

- `{{entity.name}}` -- Entity display name

- `{{entity.owners}}` -- Entity owners

- `{{entity.description}}` -- Entity description

- `{{entity.href}}` -- Direct link to the entity

- And more

Add conditional logic and rich formatting

Templates support conditional formatting with `{{#if}}`, `{{else}}`, and `{{/if}}` blocks. The rich text editor lets you add bold, italic, code blocks, images, links to assets, and other formatting.

Validate before saving

Click Validate to check your template syntax before saving. Invalid placeholders or syntax errors are highlighted so you can fix them before deployment.

Flexible template assignment

When creating an alert, choose to use the system default template, select a custom template from your organization's library, or create a new template specific to that alert. You can also configure alerts to notify downstream asset owners with customizable depth settings.

## Breaking Changes

### Elasticsearch & Opensearch Version Changes

1. **Elasticsearch server version**: Verify whether the server is running version 8.x. If it is running an earlier version, please upgrade to 8.x before proceeding.
2. **OpenSearch server version**: Verify whether the server is running version 2.x. If it is running an earlier version, please upgrade to 2.x before proceeding.

### Deprecating Python 3.9

Python 3.9 became EOL in October 2025, and most of the Ingestion Framework dependencies already dropped its support.

We are now removing support for Python 3.9 in the ingestion framework and adding support for Python 3.12.

### Airflow 3.X will be the new default

As part of the python changes, we're also updating the default OSS ingestion image to be based on Airflow 3.X.

If you are still using 2.10.X in your own custom images, we will still support that version.

POST `api/v1/dataQuality/testCases` Permission Change

We previously enforced the `EditTests` operations on the `Table` resource for creating test case permission. We have now introduced a new `CreateTests` operation on the `Table` resource for finer grain permission control over create vs edit tests for Table entities.

If you previously had an `EditTests` operation for a `Table` resource on your policy meant to prevent creation of test cases you will need to add the `CreatTests` operation as part of your policy.

## Changelog

### Features

- Kafka Connect: support for Confluent Cloud connectors
- AWS Kinesis Firehose connector (OSS)
- Hex dashboard connector support
- Salesforce OAuth and related connector improvements
- Collibra metadata connector
- Various UI features: pagination for child glossary terms, project explore card, pipeline view node/edge support, contract tab support for entities
- Add `table2.keyColumns` parameter for table diff validation

### Improvements

- Iceberg load table: retry backoff improvements
- Pagination for Snowflake usage and lineage queries
- Unity Catalog lineage enhancements (external location support, S3 lineage fixes)
- Kafka Connect and Databricks DLT pipeline parsing improvements
- Unified Elasticsearch/OpenSearch client API and index management
- Search refactorings and performance fixes (timeouts, query improvements)
- Notification templates: richer formatting, validation, and preview
- Add custom property fields to search settings
- Support for coverImage uploads
- Optional Redis caching for improved performance

### Fixes

- Fix: GlossaryTerm circular parent references causing API hangs (directChildrenOf)
- Fix: Domain assets count mismatch between API and UI
- Fix: PowerBI Snowflake query lineage parsing and dataset source fixes
- Fix: Domain assets API not returning all assets due to query size limits
- Fix: Security select dropdown in DataContract
- Fix: Prevent duplicate notification on cover image upload failures
- Fix: Workflow API runner values and related workflow issues
- Fix: Logs page infinite scroll and socket timeout issues
- Fix: User creation through openmetadata-ops.sh
- Fix: Hide "Add" owner/domain when classification is disabled
- Fix: Teams page breadcrumb URL
- Fix: UC ingestion failing for non-selected tables
- Fix: Assets lost on tag/term rename after prior changes
- Fix: Various BigQuery, Snowflake, and DBT-related issues
- Fix: Notification publishers to use Handlebars templates and related template bugs
- Fix: Several failing UI tests and flaky E2E test stability improvements

### Security & Compatibility

- Vulnerability fix for org.json
- Code-scanning fixes for string escaping/encoding and insecure randomness
- Security fixes for angus mail vulnerability and dependency upgrades
- Pin `pydantic` to &lt;2.12.0 to avoid recent breaking changes
- Add FORCE_SECURE_SESSION_COOKIE and LDAP/SSO robustness improvements

### Migrations & Upgrades

- Move migrations to 1.11.x and related migration fixes (1.10.x adjustments)
- Remove deprecated `defaultTemplateChecksum` field via migration
- Truncate Flowable tables in targeted migrations for safety
- Add migration to update NLQ settings

### Connectors & Integrations

- Kafka lineage for Databricks pipelines
- PowerBI: native query lineage extraction for Databricks
- Hex dashboard connector and Collibra connector additions
- BigQuery, Snowflake, Trino: SQL Studio support and fixes
